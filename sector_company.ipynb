{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5ad9f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f64a77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_keys(dict_curr):\n",
    "    keys_0 = []\n",
    "    for j,i in zip(dict_curr.keys(),dict_curr.values()):\n",
    "        if i==0:\n",
    "            keys_0.append(j)\n",
    "    for i in keys_0:\n",
    "        dict_curr.pop(i)\n",
    "    return dict_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0b40e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_aggregation(start_time,end_time):    \n",
    "    df = pd.read_csv('company_meta_final.csv')\n",
    "    index_timeline_list = []\n",
    "    index_timeline = start_time\n",
    "    while(index_timeline<=end_time):\n",
    "        index_timeline_list.append(index_timeline)\n",
    "        index_timeline = index_timeline+timedelta(days=1)\n",
    "    list_sector = list(df.sector.unique())\n",
    "\n",
    "\n",
    "    dict_common = {}\n",
    "    dict_us = {}\n",
    "    dict_canada = {}\n",
    "    dict_india = {}\n",
    "    dict_japan = {}\n",
    "    dict_china = {}\n",
    "    dict_uk = {}\n",
    "\n",
    "    for sector_range in list_sector:\n",
    "        for index_timeline_list_value in index_timeline_list:\n",
    "            dict_common[str(sector_range)+'/'+str(index_timeline_list_value)] = 0\n",
    "            dict_us[str(sector_range)+'/'+str(index_timeline_list_value)] = 0\n",
    "            dict_canada[str(sector_range)+'/'+str(index_timeline_list_value)] = 0\n",
    "            dict_india[str(sector_range)+'/'+str(index_timeline_list_value)] = 0\n",
    "            dict_japan[str(sector_range)+'/'+str(index_timeline_list_value)] = 0\n",
    "            dict_china[str(sector_range)+'/'+str(index_timeline_list_value)] = 0\n",
    "            dict_uk[str(sector_range)+'/'+str(index_timeline_list_value)] = 0\n",
    "\n",
    "    dict_common_main = {}\n",
    "    dict_us_main = {}\n",
    "    dict_canada_main = {}\n",
    "    dict_india_main = {}\n",
    "    dict_japan_main = {}\n",
    "    dict_china_main = {}\n",
    "    dict_uk_main = {}\n",
    "\n",
    "    dict_us_volume = {}\n",
    "    dict_canada_volume = {}\n",
    "    dict_india_volume = {}\n",
    "    dict_japan_volume = {}\n",
    "    dict_china_volume = {}\n",
    "    dict_uk_volume = {}\n",
    "\n",
    "\n",
    "    for index_timeline_list_value in index_timeline_list:\n",
    "        dict_common_main[str(index_timeline_list_value)] = 0\n",
    "        dict_us_main[str(index_timeline_list_value)] = 0\n",
    "        dict_canada_main[str(index_timeline_list_value)] = 0\n",
    "        dict_india_main[str(index_timeline_list_value)] = 0\n",
    "        dict_japan_main[str(index_timeline_list_value)] = 0\n",
    "        dict_china_main[str(index_timeline_list_value)] = 0\n",
    "        dict_uk_main[str(index_timeline_list_value)] = 0\n",
    "\n",
    "        dict_us_volume[str(index_timeline_list_value)] = 0\n",
    "        dict_canada_volume[str(index_timeline_list_value)] = 0\n",
    "        dict_india_volume[str(index_timeline_list_value)] = 0\n",
    "        dict_japan_volume[str(index_timeline_list_value)] = 0\n",
    "        dict_china_volume[str(index_timeline_list_value)] = 0\n",
    "        dict_uk_volume[str(index_timeline_list_value)] = 0\n",
    "\n",
    "\n",
    "\n",
    "    for df_values in df.values:\n",
    "\n",
    "        df_company_data = pd.read_csv('./company_stock_data_usd/'+ df_values[0]+'.csv')\n",
    "\n",
    "        date_new = []\n",
    "        for i in df_company_data['Date']:\n",
    "            date_new.append(datetime.strptime(i, '%Y-%m-%d'))\n",
    "        df_company_data['Date'] = date_new\n",
    "\n",
    "\n",
    "        df_computed = df_company_data[['Date', 'OpenUSD','Volume']][(df_company_data['Date']>=start_time) & (df_company_data['Date']<=end_time) & (df_company_data['OpenUSD'].notnull()) & (df_company_data['Date'].notnull()) & (df_company_data['Volume'].notnull())]\n",
    "\n",
    "        for compute_value in df_computed.values:\n",
    "\n",
    "            if (df_values[2]+'/'+(str(compute_value[0]))) in list(dict_common.keys()):\n",
    "\n",
    "                dict_common[df_values[2]+'/'+(str(compute_value[0]))] = dict_common[df_values[2]+'/'+(str(compute_value[0]))] + compute_value[1]\n",
    "\n",
    "                if df_values[4] == 'United States' or df_values[4] == 'Ireland':\n",
    "                    dict_us[df_values[2]+'/'+(str(compute_value[0]))] = dict_us[df_values[2]+'/'+(str(compute_value[0]))] + compute_value[1]\n",
    "\n",
    "                elif df_values[4] == 'Canada':\n",
    "                    dict_canada[df_values[2]+'/'+(str(compute_value[0]))] = dict_canada[df_values[2]+'/'+(str(compute_value[0]))] + compute_value[1]\n",
    "\n",
    "                elif df_values[4] == 'India':\n",
    "                    dict_india[df_values[2]+'/'+(str(compute_value[0]))] = dict_india[df_values[2]+'/'+(str(compute_value[0]))] + compute_value[1]\n",
    "\n",
    "                elif df_values[4] == 'China' or df_values[4] == 'Hong Kong' or df_values[4] == 'Singapore' or df_values[0] == '0005.HK':\n",
    "                    dict_china[df_values[2]+'/'+(str(compute_value[0]))] = dict_china[df_values[2]+'/'+(str(compute_value[0]))] + compute_value[1]\n",
    "\n",
    "                elif df_values[4] == 'Japan':\n",
    "                    dict_japan[df_values[2]+'/'+(str(compute_value[0]))] = dict_japan[df_values[2]+'/'+(str(compute_value[0]))] + compute_value[1]\n",
    "\n",
    "                elif df_values[4] == 'United Kingdom' and df_values[0]!= '0005.HK':\n",
    "                    dict_uk[df_values[2]+'/'+(str(compute_value[0]))] = dict_uk[df_values[2]+'/'+(str(compute_value[0]))] + compute_value[1]\n",
    "\n",
    "        for compute_value in df_computed.values:\n",
    "\n",
    "            if ((str(compute_value[0]))) in list(dict_common_main.keys()):\n",
    "\n",
    "                dict_common_main[(str(compute_value[0]))] = dict_common_main[(str(compute_value[0]))] + compute_value[1]\n",
    "\n",
    "                if df_values[4] == 'United States' or df_values[4] == 'Ireland':\n",
    "                    dict_us_main[(str(compute_value[0]))] = dict_us_main[(str(compute_value[0]))] + compute_value[1]\n",
    "                    dict_us_volume[(str(compute_value[0]))] = dict_us_volume[(str(compute_value[0]))] + compute_value[2]\n",
    "\n",
    "                elif df_values[4] == 'Canada':\n",
    "                    dict_canada_main[(str(compute_value[0]))] = dict_canada_main[(str(compute_value[0]))] + compute_value[1]\n",
    "                    dict_canada_volume[(str(compute_value[0]))] = dict_canada_volume[(str(compute_value[0]))] + compute_value[2]\n",
    "\n",
    "                elif df_values[4] == 'India':\n",
    "                    dict_india_main[(str(compute_value[0]))] = dict_india_main[(str(compute_value[0]))] + compute_value[1]\n",
    "                    dict_india_volume[(str(compute_value[0]))] = dict_india_volume[(str(compute_value[0]))] + compute_value[2]\n",
    "\n",
    "                elif df_values[4] == 'China' or df_values[4] == 'Hong Kong' or df_values[4] == 'Singapore' or df_values[0] == '0005.HK':\n",
    "                    dict_china_main[(str(compute_value[0]))] = dict_china_main[(str(compute_value[0]))] + compute_value[1]\n",
    "                    dict_china_volume[(str(compute_value[0]))] = dict_china_volume[(str(compute_value[0]))] + compute_value[2]\n",
    "\n",
    "                elif df_values[4] == 'Japan':\n",
    "                    dict_japan_main[(str(compute_value[0]))] = dict_japan_main[(str(compute_value[0]))] + compute_value[1]\n",
    "                    dict_japan_volume[(str(compute_value[0]))] = dict_japan_volume[(str(compute_value[0]))] + compute_value[2]\n",
    "\n",
    "                elif df_values[4] == 'United Kingdom' and df_values[0]!= '0005.HK':\n",
    "                    dict_uk_main[(str(compute_value[0]))] = dict_uk_main[(str(compute_value[0]))] + compute_value[1]\n",
    "                    dict_uk_volume[(str(compute_value[0]))] = dict_uk_volume[(str(compute_value[0]))] + compute_value[2]\n",
    "\n",
    "\n",
    "\n",
    "    dict_common = remove_keys(dict_common)\n",
    "    dict_us = remove_keys(dict_us)\n",
    "    dict_canada = remove_keys(dict_canada)\n",
    "    dict_india = remove_keys(dict_india)\n",
    "    dict_japan = remove_keys(dict_japan)\n",
    "    dict_china = remove_keys(dict_china)\n",
    "    dict_uk = remove_keys(dict_uk)\n",
    "\n",
    "    dict_common_main = remove_keys(dict_common_main)\n",
    "    dict_us_main = remove_keys(dict_us_main)\n",
    "    dict_canada_main = remove_keys(dict_canada_main)\n",
    "    dict_india_main = remove_keys(dict_india_main)\n",
    "    dict_japan_main = remove_keys(dict_japan_main)\n",
    "    dict_china_main = remove_keys(dict_china_main)\n",
    "    dict_uk_main = remove_keys(dict_uk_main)\n",
    "\n",
    "    dict_us_volume = remove_keys(dict_us_volume)\n",
    "    dict_canada_volume = remove_keys(dict_canada_volume)\n",
    "    dict_india_volume = remove_keys(dict_india_volume)\n",
    "    dict_japan_volume = remove_keys(dict_japan_volume)\n",
    "    dict_china_volume = remove_keys(dict_china_volume)\n",
    "    dict_uk_volume = remove_keys(dict_uk_volume)\n",
    "    \n",
    "    return dict_common, dict_us, dict_canada, dict_india, dict_japan, dict_china, dict_uk, dict_common_main, dict_us_main, dict_canada_main, dict_india_main, dict_japan_main, dict_china_main, dict_uk_main, dict_us_volume, dict_canada_volume, dict_india_volume, dict_japan_volume, dict_china_volume, dict_uk_volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f9aa0b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_csvs_sector(dict_last,folder_name,howmuch):    \n",
    "    df_fg = pd.DataFrame.from_dict(dict_last, orient='index', columns=['Open'])\n",
    "    list_to_sep_sector = []\n",
    "    list_to_sep_date = []\n",
    "    for i in df_fg.index:\n",
    "        k,l = i.split('/')\n",
    "        list_to_sep_sector.append(k)\n",
    "        list_to_sep_date.append(l)\n",
    "    df_fg['Date'] = list_to_sep_date\n",
    "    df_fg['Sector'] = list_to_sep_sector\n",
    "\n",
    "    df_fg.reset_index(drop=True, inplace=True)\n",
    "    df_fg.to_csv('./History/'+folder_name+'/Sector/'+'sector_'+folder_name+'_'+howmuch+'.csv',index='False')\n",
    "\n",
    "def creating_csvs_main(dict_last,folder_name,howmuch,isvolume=0):\n",
    "    \n",
    "    if isvolume == 0:\n",
    "        df_fg = pd.DataFrame.from_dict(dict_last, orient='index', columns=['Open'])\n",
    "    else:\n",
    "        df_fg = pd.DataFrame.from_dict(dict_last, orient='index', columns=['Volume'])\n",
    "        \n",
    "    list_to_sep_date = []\n",
    "    for i in df_fg.index:\n",
    "        list_to_sep_date.append(i)\n",
    "    df_fg['Date'] = list_to_sep_date\n",
    "    df_fg.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    if isvolume == 0:\n",
    "        df_fg.to_csv('./History/'+folder_name+'/noSector/'+'nosector_'+folder_name+'_'+howmuch+'.csv',index='False')\n",
    "    else:\n",
    "        df_fg.to_csv('./History/'+folder_name+'/noSector/'+'nosector_volume_'+folder_name+'_'+howmuch+'.csv',index='False')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "45ff79df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-9-11\n",
      "['2001-09-11', '2002-03-11']\n",
      "financial-us\n",
      "['2007-12-01', '2009-06-30']\n",
      "covid-19\n",
      "['2020-01-20', '2021-12-01']\n",
      "russia-ukraine\n",
      "['2022-02-24', '2022-04-15']\n",
      "chinese-crash\n",
      "['2015-06-01', '2016-03-01']\n",
      "japan-tsunami\n",
      "['2011-03-05', '2011-10-05']\n"
     ]
    }
   ],
   "source": [
    "folder_dict = {'us-9-11':['2001-09-11','2002-03-11'],\n",
    "               'financial-us':['2007-12-01','2009-06-30'],\n",
    "               'covid-19':['2020-01-20','2021-12-01'],\n",
    "               'russia-ukraine':['2022-02-24','2022-04-15'],\n",
    "               'chinese-crash':['2015-06-01','2016-03-01'],\n",
    "               'japan-tsunami':['2011-03-05','2011-10-05']}\n",
    "\n",
    "countries = ['all','us','canada','india','japan','china','uk']\n",
    "\n",
    "for folder,time_period in zip(folder_dict.keys(),folder_dict.values()):\n",
    "    print(folder)\n",
    "    print(time_period)\n",
    "    \n",
    "    start_time = datetime.strptime(time_period[0], '%Y-%m-%d')\n",
    "    end_time = datetime.strptime(time_period[1], '%Y-%m-%d')\n",
    "    \n",
    "    dict_common, dict_us, dict_canada, dict_india, dict_japan, dict_china, dict_uk, dict_common_main, dict_us_main, dict_canada_main, dict_india_main, dict_japan_main, dict_china_main, dict_uk_main, dict_us_volume, dict_canada_volume, dict_india_volume, dict_japan_volume, dict_china_volume, dict_uk_volume = find_aggregation(start_time,end_time)\n",
    "    \n",
    "    list_sector = [dict_common,dict_us,dict_canada,dict_india,dict_japan,dict_china,dict_uk]\n",
    "    list_main = [dict_common_main,dict_us_main,dict_canada_main,dict_india_main,dict_japan_main,dict_china_main,dict_uk_main]\n",
    "    list_volume = [dict_us_volume,dict_canada_volume,dict_india_volume,dict_japan_volume,dict_china_volume,dict_uk_volume]\n",
    "    \n",
    "    for run_sector,country in zip(list_sector,countries):\n",
    "        creating_csvs_sector(run_sector, folder, country)\n",
    "        \n",
    "    for run_main,country in zip(list_main,countries):\n",
    "        creating_csvs_main(run_main, folder, country)\n",
    "        \n",
    "    for run_sector,country in zip(list_volume,countries[1:]):\n",
    "        creating_csvs_main(run_sector, folder, country,isvolume=1)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8efad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
